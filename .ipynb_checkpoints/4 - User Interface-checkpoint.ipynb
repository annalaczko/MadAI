{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e4867f21-acc8-4a8a-bb24-1403f40a7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bd2eb4aa-abe0-45d6-ad8a-117199d60f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model elmentése\n",
    "# ki kellene találni, hogy mi lesz ha több modelt kell elmentenünk\n",
    "# szükséges ahhoz, hogy a gradio működjön\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "769e5b66-189b-4259-9cb3-f5ce17413546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(item):\n",
    "    pixel = item\n",
    "    minimum = pixel.min()\n",
    "    maximum = pixel.max()\n",
    "\n",
    "    if minimum < 0:\n",
    "        pixel = pixel + abs(minimum)\n",
    "        maximum += abs(minimum)\n",
    "        \n",
    "    if maximum != 0:\n",
    "        pixel = pixel / maximum\n",
    "    return pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4c2e79d0-b013-4ab5-9237-43f0ac446e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, dicom, file_format):\n",
    "    num=1\n",
    "    if (file_format=='DICOM'):\n",
    "        num=len(dicom)\n",
    "    images=[]\n",
    "    \n",
    "    for i in range(num):\n",
    "        if (file_format=='DICOM'):\n",
    "            dicom_image=pydicom.dcmread(dicom[i])  \n",
    "            gray_image=dicom_image.pixel_array\n",
    "        else:\n",
    "            img = Image.fromarray(np.uint8(image))   \n",
    "            gray_image = img.convert('L')\n",
    "        \n",
    "        image_array = np.array(gray_image)\n",
    "        resized_image = cv2.resize(image_array, (256, 256))\n",
    "        normalized_image=normalize(resized_image)\n",
    "        images.append(normalized_image)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "47cbcd5b-72ee-40eb-aba2-04c3d34f3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing (gender, age_group, file_format, dicom, image):\n",
    "    cols=['Is_Male', 'Age_Group_3', 'Age_Group_4', 'Age_Group_5', 'Age_Group_6', 'Age_Group_7', 'Age_Group_8', 'Image']\n",
    "    cols_age=[ 'Age_Group_3', 'Age_Group_4', 'Age_Group_5', 'Age_Group_6', 'Age_Group_7', 'Age_Group_8']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    #image\n",
    "    proc_img=preprocess_image(image, dicom, file_format)\n",
    "    if (len(proc_img)==1):\n",
    "        df.loc[0, 'Image']=proc_img\n",
    "    else:\n",
    "        for i in range(len(proc_img)):\n",
    "            df.loc[i, 'Image']=proc_img[i]\n",
    "\n",
    "    df['Image'] = df['Image'].apply(lambda x: np.array(x).flatten())\n",
    "    \n",
    "    #age_group\n",
    "    for item in cols_age:\n",
    "        if (int(item[10])==int(age_group[0])-1):\n",
    "            df[item]=True\n",
    "        else:\n",
    "            df[item]=False\n",
    "    #gender\n",
    "    if (gender=='Male'):\n",
    "        df['Is_Male']=True\n",
    "    else:\n",
    "        df['Is_Male']=False\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e302776a-9edf-44c8-a67b-3b149c031d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(gender, age_group, file_format, dicom, image):\n",
    "    df=preprocessing(gender, age_group, file_format, dicom, image)\n",
    "    image_classifier=joblib.load('model_image.joblib')\n",
    "    patient_data_classifier=joblib.load('model_patient_data.joblib')\n",
    "\n",
    "    df_image=df['Image'].tolist()\n",
    "\n",
    "    print (df_image)\n",
    "    df_patient_data=df.drop('Image', axis=1)\n",
    "\n",
    "    y_image=image_classifier.predict(df_image)\n",
    "\n",
    "    labels = {0: 'Normal', 1: 'Heart failure with infarct', 2: 'Heart failure without infarct', 3: 'Hypertrophy'}\n",
    "\n",
    "    if (len(y_image)==1):\n",
    "        return labels[y_image[0]]\n",
    "    else:\n",
    "        result=mode(y_image)\n",
    "\n",
    "        print(result.mode)\n",
    "        string=f\"{labels[result.mode]} with an {result.count/len(y_image)*100}% certainty\"\n",
    "        \n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2bbe7167-e4d2-4c24-a022-502f196717f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7913\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7913/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.])]\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13488\\4247799954.py\", line 21, in model_predict\n",
      "    string=f\"{labels[result.mode[0]]} with an {result.count[0]/len(y_image)*100}% certainty\"\n",
      "                     ~~~~~~~~~~~^^^\n",
      "IndexError: invalid index to scalar variable.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\queueing.py\", line 456, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1522, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1144, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\utils.py\", line 674, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13488\\4247799954.py\", line 21, in model_predict\n",
      "    string=f\"{labels[result.mode[0]]} with an {result.count[0]/len(y_image)*100}% certainty\"\n",
      "                     ~~~~~~~~~~~^^^\n",
      "IndexError: invalid index to scalar variable.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\queueing.py\", line 501, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\queueing.py\", line 465, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n"
     ]
    }
   ],
   "source": [
    "options_gender= ['Female', 'Male']\n",
    "options_age_group=['40 or younger', '41-50', '51-60', '61-70', '71-80', '81 or older']\n",
    "options_file_upload=['DICOM', 'Other Image Format']\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=model_predict,\n",
    "    inputs=[\n",
    "        gr.Radio(options_gender, label=\"Patient's gender\"),\n",
    "        gr.Radio(options_age_group, label=\"Patient's age\"),\n",
    "        gr.Radio(options_file_upload, label=\"Choose your file format! You can upload several files with dicom format, but only one image\"), \n",
    "        gr.File(label=\"Upload your DICOM file!\", file_count='multiple'),\n",
    "        gr.Image(label='Upload your picture!')],\n",
    "    outputs=gr.Textbox(label=\"Diagnosis\")\n",
    ")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(inbrowser=True, show_api=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9e996b-d159-41b8-9598-47760d967a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
